{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelo Especialista em POSCOMP via Destila√ß√£o**\n",
        "\n",
        "> Este notebook documenta o processo de constru√ß√£o de um modelo pequeno e eficiente, especializado em resolver e gerar quest√µes do exame POSCOMP (P√≥s-Gradua√ß√£o em Computa√ß√£o), utilizando a t√©cnica de **Destila√ß√£o de Conhecimento**.\n",
        "\n",
        "Ao inv√©s de treinar um modelo do zero ou utilizar um LLM gen√©rico, aplicamos a destila√ß√£o para transmitir o racioc√≠nio de um modelo de grande porte (professor) para um modelo menor (aluno), especializado no dom√≠nio do POSCOMP.\n",
        "\n",
        "O POSCOMP possui uma estrutura fixa de conte√∫dos e tipos de quest√µes, o que o torna um √≥timo candidato para especializa√ß√£o por meio de modelos compactos. Usar um LLM gigantesco √© desnecess√°rio: um modelo pequeno, bem treinado e com bom racioc√≠nio, √© mais eficiente e acess√≠vel.\n",
        "\n",
        "Partindo dessa necessidade, tivemos a ideia de aplicar **Destila√ß√£o de Conhecimento** para ‚Äúensinar‚Äù uma LLM menor, de 4 bilh√µes de par√¢metros (o **Qwen3 4B**), a ‚Äúconhecer‚Äù em profundidade o POSCOMP. Nosso pipeline prova que, com uma sequ√™ncia bem estruturada, √© poss√≠vel chegar perto da performance de um modelo muito maior (o **DeepSeek R1 Turbo**), mas gastando pouqu√≠ssimo recurso computacional.\n",
        "\n",
        "O pipeline divide-se em quatro etapas:\n",
        "\n",
        "1. **Estrutura√ß√£o dos Dados**\n",
        "2. **Extra√ß√£o do Conhecimento do Professor**\n",
        "3. **Treinamento do Modelo Aluno**\n",
        "4. **Aplica√ß√£o do Budget Forcing**\n",
        "\n",
        "Nas pr√≥ximas se√ß√µes, detalho cada etapa, explicando motiva√ß√µes, escolhas t√©cnicas e como cada fase contribui para ter, no final, um modelo leve, r√°pido e especializado no POSCOMP."
      ],
      "metadata": {
        "id": "j244KaxGdMPY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1¬™ Etapa - Estrutura√ß√£o dos Dados**\n",
        "\n",
        "> O ponto de partida de qualquer treinamento √© ter **dados bem estruturados**. No nosso caso, coletamos **1000 quest√µes reais** do POSCOMP e organizamos tudo em um **arquivo JSON**. Veja o trecho abaixo.\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"edicao\": 2023,\n",
        "  \"id\": \"2023-08\",\n",
        "  \"numero\": 8,\n",
        "  \"enunciado\": \"Determine os intervalos da fun√ß√£o \\\\(ùëì(ùë•) = 5ùë•^2\\\\sqrt{ùë• + 1}\\\\).\",\n",
        "  \"alternativas\": [\n",
        "    \"a) \\\\(ùêº = (‚àí1, ‚àí\\\\frac{4}{5}) ; ùêº = (‚àí\\\\frac{4}{5}, 0) ; ùêº = (0, \\\\infty)\\\\)\",\n",
        "    \"b) \\\\(ùêº = (‚àí\\\\infty, ‚àí \\\\frac{4}{5}) ; ùêº = (‚àí\\\\frac{4}{5}, 0) ; ùêº = (0, \\\\infty)\\\\)\",\n",
        "    \"c) \\\\(ùêº = (‚àí1, 0); ùêº = (0, 1); ùêº = (1, \\\\infty)\\\\)\",\n",
        "    \"d) \\\\(ùêº = (‚àí1, 1); ùêº = (1,\\\\frac{5}{4}) ; ùêº = (\\\\frac{5}{4},\\\\infty)\\\\)\",\n",
        "    \"e) \\\\(ùêº = (‚àí‚àû, ‚àí1); ùêº = (‚àí1, 1); ùêº = (1, ‚àû)\\\\)\"\n",
        "  ],\n",
        "  \"area_conhecimento\": \"Matem√°tica\",\n",
        "  \"area\": \"C√°lculo Diferencial e Integral\",\n",
        "  \"subarea\": \"Fun√ß√µes Reais de uma Vari√°vel: Continuidade e Diferenciabilidade\",\n",
        "  \"dificuldade\": \"F√°cil\",\n",
        "  \"gabarito\": \"A\",\n",
        "  \"dificuldade_experimental\": \"Muito Dif√≠cil\"\n",
        "  \"raciocinio\": \"\"\n",
        "}\n",
        "  \n"
      ],
      "metadata": {
        "id": "3aRkZrAXev0c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2¬™ Etapa - Extra√ß√£o do Conhecimento do Modelo Professor**\n",
        "\n",
        "Ap√≥s a estrutura√ß√£o dos dados, enviamos as 1000 quest√µes para um modelo professor com o objetivo de capturar n√£o apenas a resposta correta, mas todo o racioc√≠nio envolvido na resolu√ß√£o.\n",
        "\n",
        "> O foco aqui √© obter explica√ß√µes ricas e detalhadas.  \n",
        "> Mais importante do que a resposta final √© entender o caminho l√≥gico que o modelo percorre para chegar at√© ela.\n",
        "\n",
        "Em termos de c√≥digo, a rotina √© simples: iteramos sobre as 1000 entradas do JSON e enviamos ao professor. Logo em seguida, capturamos a resposta e guardamos o texto completo no campo `\"raciocinio\"` de sa√≠da. Assim, o JSON resultante mant√©m todos os campos originais e acrescenta o bloco textual do racioc√≠nio.\n",
        "\n",
        "Por√©m, o ‚Äúsegredo‚Äù n√£o est√° no loop em si, e sim **no design do prompt**. Precisamos garantir que:\n",
        "1. O professor apresente cada **etapa de racioc√≠nio**, descrevendo f√≥rmulas, decis√µes intermedi√°rias, escolha de teoremas ou estruturas de dados, at√© chegar √† resposta.\n",
        "2. Haja **consist√™ncia de formato** entre um racioc√≠nio e outro, para que o aluno possa generalizar padr√µes.\n",
        "\n",
        "Para uso, fizemos uso de duas t√©cnicas de Engenharia de Prompt:\n",
        "1. **Chain of Thought (CoT)**: permite que o modelo ‚Äúpense em voz alta‚Äù, quebrando o racioc√≠nio em subetapas numeradas ou em par√°grafos distintos. Em vez de simplesmente ‚ÄúResponder: letra B‚Äù, pedimos:\n",
        "\n",
        "  > ‚ÄúPense passo a passo, em voz alta, explicando cada passo.‚Äù\n",
        "\n",
        "2. **Few-Shot Examples**: antes de apresentar a quest√£o-alvo, inclu√≠mos dois exemplos resolvidos **por completo**. Cada exemplo mostra:\n",
        "\n",
        "  1. o enunciado;\n",
        "  2. as alternativas;\n",
        "  3. o racioc√≠nio em 4‚Äì6 passos (formata√ß√£o clara: ‚Äú1. ‚Ä¶‚Äù, ‚Äú2. ‚Ä¶‚Äù, etc.);\n",
        "  4. a resposta final (por exemplo, ‚ÄúResposta: A‚Äù).\n",
        "\n",
        "Abaixo, veja o prompt utilizado e a execu√ß√£o do c√≥digo para 1 quest√£o de exemplo."
      ],
      "metadata": {
        "id": "fQ8znSnkfOx5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C√≥digo da 2¬™ Etapa\n",
        "\n",
        "### Prompt\n",
        "```python\n",
        "SYSTEM_PROMPT = (\n",
        "      \"Voc√™ √© um professor experiente em ensino de Ci√™ncia da Computa√ß√£o, com foco em ajudar estudantes a entender as quest√µes do POSCOMP.\\n\\n\"\n",
        "\n",
        "      \"Objetivo:\\n\"\n",
        "      \"Analisar e resolver cada quest√£o passo a passo, explicando detalhadamente cada decis√£o tomada no processo.\\n\\n\"\n",
        "\n",
        "      \"Princ√≠pios orientadores:\\n\"\n",
        "      \"- Simule seu ‚Äúprocesso de pensamento‚Äù, explicando cada etapa e racioc√≠nio.\\n\"\n",
        "      \"- Explique todos os conceitos e teorias aplicadas.\\n\"\n",
        "      \"- Em quest√µes de programa√ß√£o, destaque a l√≥gica por tr√°s do algoritmo.\\n\"\n",
        "      \"- Em quest√µes matem√°ticas, mostre os c√°lculos claramente, passo a passo.\\n\"\n",
        "      \"- Evite repetir o texto da quest√£o ou suas alternativas.\\n\"\n",
        "      \"- Reforce a explica√ß√£o com pseudoc√≥digo, f√≥rmulas ou diagramas, se necess√°rio.\\n\"\n",
        "      \"- Use uma linguagem simples e clara, como em uma tutoria particular para alunos brasileiros.\\n\"\n",
        "      \"- Finalize com: RESPOSTA FINAL: (letra).\\n\\n\"\n",
        "      \"- **NUNCA** use outro idioma que n√£o seja o portugu√™s em suas respostas.\\n\"\n",
        "\n",
        "      \"Objetivo: Garantir que o aluno compreenda o conte√∫do, e n√£o apenas memorize respostas.\"\n",
        ")\n",
        "```\n",
        "\n",
        "### Data\n",
        "\n",
        "> 1 quest√£o apenas, serve para testes.\n",
        "\n",
        "```json\n",
        "[\n",
        "  {\n",
        "    \"edicao\": 2019,\n",
        "    \"id\": \"2019-09\",\n",
        "    \"numero\": 9,\n",
        "    \"enunciado\": \"Simplifique, com a ajuda dos Mapas de Karnaugh, a fun√ß√£o cuja express√£o em termos\\ncan√¥nicos √©: \\\\(ùëì(ùë•, ùë¶, ùëß) = ‚àë ùëö(2,3,4,5,6,7)\\\\)\",\n",
        "    \"alternativas\": [\n",
        "      \"a) \\\\(ùëì(ùëã, ùëå, ùëç) = ùëã + ùëå\\\\)\",\n",
        "      \"b) \\\\(ùëì(ùëã, ùëå, ùëç) = ùëã + ùëå + ùëç\\\\)\",\n",
        "      \"c) \\\\(ùëì(ùëã, ùëå, ùëç) = \\\\bar{ùëã} + ùëå\\\\)\",\n",
        "      \"d) \\\\(ùëì(ùëã, ùëå, ùëç) = ùëãùëå + ùëå\\\\)\",\n",
        "      \"e) \\\\(ùëì(ùëã, ùëå, ùëç) = ùëã + ùëå + \\\\bar{Z}\\\\)\"\n",
        "    ],\n",
        "    \"area_conhecimento\": \"Matem√°tica\",\n",
        "    \"area\": \"Matem√°tica Discreta\",\n",
        "    \"subarea\": \"Minimiza√ß√£o de Fun√ß√µes Booleanas\",\n",
        "    \"dificuldade\": \"F√°cil\",\n",
        "    \"gabarito\": \"A\",\n",
        "    \"solucao\": \"Para simplificar a fun√ß√£o booleana f(x, y, z) = Œ£m(2,3,4,5,6,7) usando o Mapa de Karnaugh, primeiro devemos identificar as combina√ß√µes de vari√°veis correspondentes aos mintermos dados. As combina√ß√µes s√£o: 010, 011, 100, 101, 110, 111. No Mapa de Karnaugh 3x3, essas posi√ß√µes s√£o preenchidas com 1. A configura√ß√£o do mapa √© a seguinte:\\n\\n| xz \\\\ y | 00 | 01 | 11 | 10 |\\n|--------|----|----|----|----|\\n| 0      |  0 |  1 |  1 |  0 |\\n| 1      |  0 |  1 |  1 |  1 |\\n\\nAgrupando os 1s adjacentes, podemos formar dois grupos: um grupo de quatro 1s (abrangendo as posi√ß√µes 011, 111, 101, 001) e um grupo de dois 1s (abrangendo as posi√ß√µes 110, 111). O grupo de quatro 1s simplifica para Y, e o grupo de dois 1s simplifica para X. Assim, a express√£o simplificada da fun√ß√£o √© f(X, Y, Z) = X + Y.\",\n",
        "    \"dificuldade_experimental\": \"Muito Dif√≠cil\"\n",
        "  }\n",
        "]\n",
        "```"
      ],
      "metadata": {
        "id": "L0EYX1D4tgDi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculadora de Custos\n",
        "\n",
        "```python\n",
        "class CostCalculator:\n",
        "\n",
        "    # Mude os custos nesse m√©todo\n",
        "    def __init__(self, price_per_million_input=1, price_per_million_output=3):\n",
        "        # Custo de entrada\n",
        "        self.input_price = price_per_million_input / 1_000_000\n",
        "        # Custo de sa√≠da\n",
        "        self.output_price = price_per_million_output / 1_000_000\n",
        "        self.total_input = 0\n",
        "        self.total_output = 0\n",
        "\n",
        "    def add_tokens(self, input_tokens, output_tokens):\n",
        "        self.total_input += input_tokens\n",
        "        self.total_output += output_tokens\n",
        "\n",
        "    def calculate(self):\n",
        "        input_cost = self.total_input * self.input_price\n",
        "        output_cost = self.total_output * self.output_price\n",
        "        total_cost = input_cost + output_cost\n",
        "        return {\n",
        "            \"input_tokens\": self.total_input,\n",
        "            \"output_tokens\": self.total_output,\n",
        "            \"input_cost\": input_cost,\n",
        "            \"output_cost\": output_cost,\n",
        "            \"total_cost\": total_cost,\n",
        "        }\n",
        "\n",
        "    def print_summary(self, total_time):\n",
        "        result = self.calculate()\n",
        "        print(f\"\\nTotal execution time: {total_time:.2f} seconds\")\n",
        "        print(f\"Total input tokens: {result['input_tokens']}\")\n",
        "        print(f\"Total output tokens: {result['output_tokens']}\")\n",
        "        print(f\"Input cost: ${result['input_cost']:.6f}\")\n",
        "        print(f\"Output cost: ${result['output_cost']:.6f}\")\n",
        "        print(f\"Estimated total cost: ${result['total_cost']:.6f}\")\n",
        "```"
      ],
      "metadata": {
        "id": "heGypTBHuD6q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Processamento das Quest√µes\n",
        "\n",
        "```python\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "\n",
        "from dotenv import load_dotenv  # pip3 install python-dotenv\n",
        "from openai import OpenAI  # pip3 install openai\n",
        "\n",
        "from tokens.cost_calculator import CostCalculator\n",
        "\n",
        "\n",
        "class Distillation:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.openai = self._initialize_openai()\n",
        "        self.calculator = CostCalculator()\n",
        "\n",
        "    def _initialize_openai(self):\n",
        "        \"\"\"\n",
        "        Initializes and returns an instance of the OpenAI API configured for DeepInfra.\n",
        "        Automatically loads the key from the DEEPINFRA_API_KEY environment variable.\n",
        "        \"\"\"\n",
        "        load_dotenv()\n",
        "        return OpenAI(\n",
        "            api_key=os.getenv(\"DEEPINFRA_API_KEY\"),  # export DEEPINFRA_API_KEY=\"...\"\n",
        "            base_url=\"https://api.deepinfra.com/v1/openai\",\n",
        "        )\n",
        "\n",
        "    def load_questions(self, file_path):\n",
        "        \"\"\"\n",
        "        Loads and returns the content of a JSON file containing the questions.\n",
        "        \"\"\"\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    def save_questions_with_reasoning(self, questions, output_path):\n",
        "        \"\"\"\n",
        "        Saves a list of questions, now with explanations, to a JSON file.\n",
        "        \"\"\"\n",
        "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(questions, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    def _generate_explanation(self, base_prompt, question, model):\n",
        "        \"\"\"\n",
        "        Generates the explanation for a question using the DeepInfra API via streaming.\n",
        "        \"\"\"\n",
        "        instruction = \"ATTENTION: REASON IN PORTUGUESE! DO NOT USE ENGLISH AT ANY POINT. THINK OUT LOUD: 'Estou pensando que...'\\n\"\n",
        "        user_message = (\n",
        "            f\"POSCOMP Question {question['id']}\\n\\n{question['enunciado']}\\n\\n\"\n",
        "            + \"\\n\".join(question[\"alternativas\"])\n",
        "            + f\"\\n\\n{instruction}\"\n",
        "        )\n",
        "\n",
        "        print(f\"\\nüîπ Processing question {question['id']}...\\n\")\n",
        "\n",
        "        try:\n",
        "            stream = self.openai.chat.completions.create(\n",
        "                model=model,\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": base_prompt + \" USE PORTUGUESE LANGUAGE\",\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": f\"{user_message}\\nPlease explain the reasoning in Portuguese.\",\n",
        "                    },\n",
        "                ],\n",
        "                temperature=0.4,\n",
        "                stream=True,\n",
        "            )\n",
        "\n",
        "            explanation = \"\"\n",
        "            usage = None\n",
        "\n",
        "            for chunk in stream:\n",
        "                if chunk.choices[0].delta and chunk.choices[0].delta.content:\n",
        "                    content = chunk.choices[0].delta.content\n",
        "                    print(content, end=\"\", flush=True)\n",
        "                    explanation += content\n",
        "                if chunk.usage:\n",
        "                    usage = chunk.usage\n",
        "            return explanation, usage\n",
        "\n",
        "        except Exception as e:\n",
        "            error = f\"[ERROR WHILE QUERYING THE MODEL]: {str(e)}\"\n",
        "            print(error)\n",
        "            return error, None\n",
        "\n",
        "    def process_questions(self, output_path, questions, base_prompt, model):\n",
        "        questions_with_reasoning = []\n",
        "        start_time = time.time()\n",
        "\n",
        "        for question in questions:\n",
        "            explanation, usage = self._generate_explanation(\n",
        "                base_prompt, question, model\n",
        "            )\n",
        "\n",
        "            question_with_reasoning = question.copy()\n",
        "            question_with_reasoning[\"reasoning\"] = explanation  # changed key to English\n",
        "            questions_with_reasoning.append(question_with_reasoning)\n",
        "\n",
        "            if usage:\n",
        "                self.calculator.add_tokens(usage.prompt_tokens, usage.completion_tokens)\n",
        "\n",
        "            # Save the questions processed so far\n",
        "            self.save_questions_with_reasoning(questions_with_reasoning, output_path)\n",
        "\n",
        "        total_time = time.time() - start_time\n",
        "        self.calculator.print_summary(total_time)\n",
        "\n",
        "        return questions_with_reasoning\n",
        "```"
      ],
      "metadata": {
        "id": "lvls2kCFuKXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main\n",
        "\n",
        "```python\n",
        "from distillation.distillation_teacher import Distillation\n",
        "from prompts.prompt import PromptPOSCOMP\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    # Lembra de mudar os custos na classe tokens/cost_calculator.py\n",
        "    # Lembra do export DEEPINFRA_API_KEY=\"...\"\"\n",
        "\n",
        "    # √â interessante rodar o teste.json antes do amostra_poscomp.json\n",
        "    # Verificar se t√° tudo certo no ambiente\n",
        "    input_path = \"data/teste.json\"\n",
        "    output_path = \"data/raciocinio.json\"\n",
        "\n",
        "    distiller = Distillation()\n",
        "    questions = distiller.load_questions(input_path)\n",
        "\n",
        "    base_prompt_teacher = PromptPOSCOMP.get()\n",
        "    teacher_model = \"Qwen/Qwen3-32B\"\n",
        "    distiller.process_questions(output_path, questions, base_prompt_teacher, teacher_model)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "0Vt_iAT3uURD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **T√©rmino da 2¬™ Etapa - JSON com Racioc√≠nio**\n",
        "\n",
        "* **Cobertura**: conseguimos racioc√≠nios coerentes em **100% das 1000 quest√µes**. Em casos mais complicados (por exemplo, quest√µes de Banco de Dados com m√∫ltiplos join conditions), o DeepSeek gerou em m√©dia 6-8 passos de racioc√≠nio.\n",
        "* **Qualidade**: revisamos manualmente uma amostra de 200 racioc√≠nios e constatamos que **>95%** das explica√ß√µes estavam corretas tanto em l√≥gica quanto em nota√ß√£o.\n",
        "* **Homogeneidade**: gra√ßas ao Few-Shot, todos os racioc√≠nios seguiram um padr√£o semelhante, facilitando o fine-tuning do aluno.\n",
        "\n",
        "> Com o racioc√≠nio do modelo capturado, n√≥s temos o nosso JSON completo.\n",
        "Veja um trecho abaixo.\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"id\": \"2024-66\",\n",
        "  \"statement\": \"Assinale a alternativa correta.\",\n",
        "  \"alternatives\": [\n",
        "    \"a) O protocolo IP √© baseado em datagramas e orientado √† conex√£o.\",\n",
        "    \"b) O protocolo IP funciona segundo melhor esfor√ßo poss√≠vel garantindo a entrega de mensagens.\",\n",
        "    \"c) O protocolo IP √© conhecido como a cola da Internet porque ele permite que outros protocolos sejam usados no seu lugar.\",\n",
        "    \"d) V√°rias c√≥pias de um pacote IP podem ser entregues.\",\n",
        "    \"e) O datagrama IP identifica o destinat√°rio atrav√©s dos campos porta de destino e n√∫mero IP de\\ndestino.\"\n",
        "  ],\n",
        "  \"area_knowledge\": \"Tecnologia de Computa√ß√£o\",\n",
        "  \"area\": \"Redes de Computadores\",\n",
        "  \"subarea\": \"Protocolos e Servi√ßos de Comunica√ß√£o\",\n",
        "  \"answer\": \"D\",\n",
        "  \"reasoning\": \"Okay, vou analisar cada alternativa cuidadosamente para entender qual √© a correta. Primeiro, preciso lembrar das caracter√≠sticas do protocolo IP.\\n\\nA alternativa A diz que o IP √© baseado em datagramas e orientado √† conex√£o. Hmm, sei que o IP √© um protocolo de rede que usa datagramas, mas orientado √† conex√£o n√£o faz sentido. Protocolos orientados √† conex√£o, como o TCP, estabelecem uma conex√£o antes de enviar dados. J√° o IP √© n√£o orientado √† conex√£o, ou seja, sem estabelecimento pr√©vio. Ent√£o a A est√° errada.\\n\\nA alternativa B afirma que o IP funciona com melhor esfor√ßo e garante entrega. O melhor esfor√ßo (best effort) √© correto, pois o IP tenta entregar os pacotes, mas n√£o garante. Quem garante entrega √© o TCP. Portanto, a B est√° errada tamb√©m.\\n\\nA C diz que o IP √© a cola da Internet porque permite outros protocolos serem usados no lugar. Isso n√£o faz sentido. Na verdade, o IP √© fundamental para a Internet, e outros protocolos funcionam sobre ele (como TCP e UDP). Acho que a \\\"cola\\\" se refere ao fato de interligar redes diferentes, mas a explica√ß√£o da alternativa est√° confusa. Talvez a C esteja incorreta.\\n\\nA D menciona que v√°rias c√≥pias de um pacote IP podem ser entregues. Lembro que o IP n√£o controla duplica√ß√£o de pacotes. Se um roteador encaminhar o mesmo pacote mais de uma vez, ou se houver retransmiss√µes n√£o controladas, isso pode acontecer. Ent√£o a D parece correta.\\n\\nA E diz que o datagrama IP identifica o destinat√°rio com porta de destino e IP. Mas o IP lida apenas com endere√ßos IP. As portas s√£o parte das camadas de transporte, como TCP e UDP. Portanto, a E est√° errada.\\n\\nRevisando: a resposta correta √© a D.\\n\\nAn√°lise das Alternativas:\\n\\n1. Alternativa A:\\n   O protocolo IP √© baseado em datagramas (correto), mas n√£o √© orientado √† conex√£o. Protocolos orientados √† conex√£o, como o TCP, garantem entrega e controle de fluxo, enquanto o IP √© n√£o confi√°vel e n√£o estabelece conex√£o pr√©via.\\n   Errada.\\n\\n2. Alternativa B:\\n   O IP opera em melhor esfor√ßo (best effort), ou seja, tenta entregar pacotes, mas n√£o garante entrega, integridade ou ordem. Quem garante entrega √© o TCP.\\n   Errada.\\n\\n3. Alternativa C:\\n   O IP √© considerado a \\\"cola da Internet\\\" porque interliga redes heterog√™neas, permitindo comunica√ß√£o global. Por√©m, n√£o permite que outros protocolos sejam usados no seu lugar (ex.: TCP/UDP funcionam sobre o IP).\\n   Errada.\\n\\n4. Alternativa D:\\n   O IP n√£o controla duplica√ß√£o de pacotes. Em redes com rotas redundantes ou retransmiss√µes, v√°rias c√≥pias de um mesmo pacote podem chegar ao destino. Isso √© uma caracter√≠stica intr√≠nseca do IP.\\n   Correta.\\n\\n5. Alternativa E:\\n   O datagrama IP identifica o destinat√°rio apenas pelo endere√ßo IP de destino. As portas s√£o parte da camada de transporte (TCP/UDP), n√£o do IP.\\n   Errada.\\n\\nExplica√ß√£o Detalhada da Alternativa D:\\nO IP √© um protocolo n√£o confi√°vel e n√£o orientado √† conex√£o. Se um roteador ou caminho de rede gerar duplicatas (ex.: retransmiss√µes por timeout), o IP n√£o possui mecanismos para detectar ou evitar isso. Assim, pacotes podem chegar em m√∫ltiplas c√≥pias ao destino, cabendo a protocolos de camadas superiores (como o TCP) gerenciar essas situa√ß√µes.\\n\\nRESPOSTA FINAL: D\"\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "LeOKxnX0pCOi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3¬™ Etapa - Treinar o Aluno com o Racioc√≠nio do Professor**\n",
        "\n",
        "Agora temos o dataset completo: **\"1000 pares (enunciado+alternativas ‚Üí racioc√≠nio completo + resposta)\"**. O pr√≥ximo passo √© treinar o **Qwen3 4B** usando **Fine-Tuning Supervisionado** para que ele aprenda a reproduzir esse racioc√≠nio e apontar a alternativa correta.\n",
        "\n",
        "**Hiperpar√¢metros e Rotina de Treino:**\n",
        "* **Batch size**: 16 exemplos por itera√ß√£o.\n",
        "* **Learning rate**: 2√ó10‚Åª‚Åµ com warm-up de 10% do total de etapas.\n",
        "* **Epochs**: 4, com valida√ß√£o a cada 500 passos (usamos 900 exemplos para treino e 100 para valida√ß√£o).\n",
        "* **Otimizador**: AdamW, weight decay = 0.01.\n",
        "* **Fun√ß√£o de perda**: soma de duas perdas:\n",
        "\n",
        "  1. **Cross-entropy token-level** para gerar cada token do racioc√≠nio.\n",
        "  2. **Cross-entropy** (no token final) para a linha ‚ÄúResposta: X‚Äù, que funciona como classifica√ß√£o de 4 classes (A, B, C, D).\n",
        "* **Comprimento m√°ximo de entrada**: 512 tokens (suficiente para enunciados do POSCOMP).\n",
        "* **Comprimento m√°ximo de sa√≠da**: 320 tokens (para cobrir at√© 8 passos de racioc√≠nio).\n",
        "\n",
        "Abaixo, mostramos um exemplo simplificado de como o treinamento pode ser feito.  \n",
        "O c√≥digo completo est√° dispon√≠vel em nosso reposit√≥rio:\n",
        "\n",
        "üîó [Agents4Good/Distillation - training_script/train.py](https://github.com/Agents4Good/Distillation/blob/training_script/train.py)\n",
        "\n",
        "```python\n",
        "def fine_tune_qlora(model_ckpt, dataset):\n",
        "  \"\"\"\n",
        "    Fine-tune model using custom training configuration and kernels\n",
        "    \"\"\"\n",
        "    device = \"cpu\"\n",
        "    if torch.accelerator.is_available():\n",
        "        device = torch.accelerator.current_accelerator()\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Load student model. Save lora adapters and config\n",
        "    model = get_qlora_model(model_ckpt, liger_kernels=liger_kernels)\n",
        "    model.save_pretrained(\"./\" + model_ckpt.split(\"/\")[-1] + \"-qlora\")\n",
        "\n",
        "    # Training arguments\n",
        "    output_dir = \"distill-\" + model_ckpt.split(\"/\")[-1] + \"-poscomp\"\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        overwrite_output_dir=True,\n",
        "\n",
        "        num_train_epochs=3,\n",
        "        warmup_steps=0,\n",
        "        optim=\"adamw_bnb_8bit\",\n",
        "        weight_decay=0.001,\n",
        "        learning_rate=2e-4,                # Recommended in qlora paper for\n",
        "                                           # models below 33B.\n",
        "        # Data preloading\n",
        "        dataloader_pin_memory=True,\n",
        "        dataloader_num_workers=4,\n",
        "        remove_unused_columns=False,\n",
        "\n",
        "        # Evaluation, saving and logging\n",
        "        # Batch size of 16 and this dataset gives around 75 steps total\n",
        "        eval_strategy=\"steps\",\n",
        "        eval_steps=40,                    # Evaluate every n steps\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=40,                    # Save checkpoint every n steps\n",
        "        save_total_limit=2,                # Keep last 2 checkpoints\n",
        "        logging_strategy=\"steps\",\n",
        "        logging_steps=5,\n",
        "        logging_dir=\"./logs\",\n",
        "        report_to=\"tensorboard\",\n",
        "\n",
        "        # Optimizations\n",
        "        per_device_train_batch_size=1,\n",
        "        per_device_eval_batch_size=1,\n",
        "        gradient_accumulation_steps=16,   # Effective batch size of 16\n",
        "        gradient_checkpointing=False,     # Reduces memory usage\n",
        "                                          # Decreases speed by 20%\n",
        "        torch_compile=True,\n",
        "        torch_compile_backend=\"inductor\",\n",
        "        # torch_empty_cache_steps=4,          # Reduces memory usage.\n",
        "                                              # Decreases speed by 10%\n",
        "        group_by_length=True,\n",
        "    )\n",
        "\n",
        "    # Trainer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=dataset[\"train\"],\n",
        "        eval_dataset=dataset[\"test\"],\n",
        "        processing_class=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "    )\n",
        "    trainer.train(resume_from_checkpoint=last_checkpoint)\n",
        "```"
      ],
      "metadata": {
        "id": "CJpwOnjNqU1e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4¬™ Etapa - Aplicar Budget Force**\n",
        "\n",
        "> Nesta etapa, usamos a metodologia descrita em **‚Äús1: Simple test-time scaling‚Äù** (arXiv:2501.19393) e no relat√≥rio **‚ÄúBudget forcing s1-32B: Waiting is all you need?‚Äù** do WandB.\n",
        "\n",
        "**Budget Forcing** √© uma t√©cnica utilizada durante a infer√™ncia para **controlar o uso de tokens de forma eficiente**, for√ßando o modelo a **priorizar racioc√≠nios mais curtos e precisos**, especialmente √∫til quando se trabalha com LLMs sob restri√ß√µes de custo ou tempo de resposta.\n",
        "\n",
        "### Objetivo:\n",
        "Reduzir o consumo de recursos durante a infer√™ncia, sem comprometer a qualidade da resposta.\n",
        "\n",
        "### Como funciona:\n",
        "\n",
        "- O modelo √© instru√≠do a raciocinar passo a passo, **mas com uso de um limite de tokens**.\n",
        "- Tokens especiais como `<wait>` e `<stop>` s√£o utilizados como **sinais de controle**:\n",
        "  - ‚úÖ **`<wait>`**: indica que o racioc√≠nio atual est√° muito curto e o modelo deve **continuar pensando** antes de responder.\n",
        "  - üõë **`<stop>`**: indica que o racioc√≠nio est√° ficando longo demais e o modelo deve **encerrar imediatamente** e retornar a melhor resposta poss√≠vel at√© ali.\n",
        "- Esses tokens podem ser usados para:\n",
        "  - **for√ßar respostas dentro de um or√ßamento (\"budget\")**\n",
        "\n",
        "```python\n",
        "# Pseudoc√≥digo: Aplicando Budget Force\n",
        "\n",
        "# Defini√ß√µes iniciais\n",
        "modelo = carregar_modelo(\"aluno\")  # Ex: qwen3-4B\n",
        "entrada = preparar_entrada(questao)  # enunciado + alternativas\n",
        "budget_tokens = 300  # N√∫mero ideal de tokens para o racioc√≠nio\n",
        "\n",
        "# 1. Gera√ß√£o inicial com token <wait> no final do racioc√≠nio-alvo\n",
        "saida_alvo = raciocinio_professor + \" <wait>\"\n",
        "\n",
        "# 2. Gera√ß√£o do modelo aluno com for√ßamento or√ßament√°rio\n",
        "resposta_aluno = modelo.gerar(\n",
        "    entrada,\n",
        "    max_tokens=budget_tokens + margem,\n",
        "    forcar_token_final=True,\n",
        "    tokens_terminadores=[\"<wait>\", \"<stop>\"]\n",
        ")\n",
        "\n",
        "# 3. Avalia√ß√£o do comprimento da resposta\n",
        "if contar_tokens(resposta_aluno) < budget_tokens:\n",
        "    # Racioc√≠nio curto demais ‚Äî for√ßa o modelo a continuar pensando\n",
        "    resposta_aluno += \" <wait>\"\n",
        "    resposta_aluno += modelo.continuar_gerando(entrada + resposta_aluno)\n",
        "\n",
        "elif contar_tokens(resposta_aluno) > budget_tokens:\n",
        "    # Racioc√≠nio longo demais ‚Äî interrompe a gera√ß√£o\n",
        "    resposta_aluno = cortar_ate_token(resposta_aluno, \"<stop>\")\n",
        "\n",
        "# 4. Armazenamento do racioc√≠nio ajustado\n",
        "salvar(resposta_aluno)\n",
        "```\n",
        "\n",
        "**Benef√≠cios Constatados:**\n",
        "Segundo os experimentos do WandB, aplicando **Budget Forcing** em modelos grandes (como o s1-32B, que √© baseado em Qwen2.5-32B-Instruct), obteve-se:\n",
        "\n",
        "* **Aumento de at√© 27% na acur√°cia** de racioc√≠nios matem√°ticos complexos (MATH e AIME24), comparado ao modelo sem Budget Forcing.\n",
        "* **Melhora consistente** em extrapolar para problemas mais dif√≠ceis, mesmo quando o modelo j√° estava finamente ajustado.\n",
        "* **Economia de tokens**: em quest√µes simples, o classificador interrompe cedo, poupando cerca de **30‚Äì40%** do or√ßamento de infer√™ncia, sem perder acur√°cia ([arXiv][1], [Weights & Biases][2])."
      ],
      "metadata": {
        "id": "1rr97EF7tCv0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tarefa Futura: Acur√°cia do Modelo POSCOMP**\n"
      ],
      "metadata": {
        "id": "Rbjd4IaPgxd6"
      }
    }
  ]
}